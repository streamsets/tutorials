Interaction with StreamSets Control Hub jobs
============================================

This set contains tutorials for [StreamSets Control Hub jobs](https://streamsets.com/documentation/controlhub/latest/help/controlhub/UserGuide/Jobs/Jobs_title.html).

A job defines the pipeline to run and the execution engine that runs the pipeline: Data Collector, Data Collector Edge, or Transformer. Jobs are the execution of the dataflow.

### Prerequisites
Before starting on any of the following tutorials, make sure to complete [Prerequisites for the jobs tutorial](preparation-for-tutorial/README.md).

### Tutorials for Jobs

1. [Sample ways to fetch one or more jobs](ways-to-fetch-jobs/README.md) - Sample ways to fetch one or more jobs.

1. [Start a job and monitor that specific job](start-monitor-a-specific-job/README.md) - Start a job and monitor that specific job using metrics and time series metrics.

1. [Move jobs from dev to prod using data_collector_labels](update-data-collector-labels/README.md) - Move jobs from dev to prod by updating data_collector label.


1. [Generate a report for a specific job](generate-a-report/README.md) - Generate a report for a specific job and then; fetch and download it.

1. [See logs for a data-collector where a job is running](data-collector-logs/README.md) - Get the DataCollector where a job is running and then see its logs.



### Conclusion

To get to know more details about SDK for Python, check the [SDK documentation](https://streamsets.com/documentation/sdk/latest/index.html).

If you don't have access to SCH, sign up for 30-day free trial by visiting https://streamsets.com/products/sch/control-hub-trial.